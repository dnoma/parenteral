{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Removal using Mask R-CNN in PyTorch - Part 1: Core Implementation\n",
    "\n",
    "This notebook demonstrates how to use Mask R-CNN to replace image backgrounds with black. The implementation is based on PyTorch and the Torchvision library.\n",
    "\n",
    "## Dataset Overview\n",
    "- Total number of images: 4,431\n",
    "- Number of categories: 413\n",
    "- Date range: 2025-02-17\n",
    "- Image formats: JPEG, MPO\n",
    "- Average dimensions: 1197x1308 pixels\n",
    "- Average file size: 265.03 KB\n",
    "\n",
    "## Data Quality Issues\n",
    "- Missing values: 5,416 total across all columns\n",
    "- Duplicate files: 0\n",
    "- Date inconsistencies: 0\n",
    "- Size outliers: 45\n",
    "- Dimension outliers: 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install torch torchvision matplotlib opencv-python tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Mask R-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained Mask R-CNN model\n",
    "weights = MaskRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "model = maskrcnn_resnet50_fpn(weights=weights)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Get COCO class names\n",
    "COCO_INSTANCE_CATEGORY_NAMES = weights.meta[\"categories\"]\n",
    "print(f\"Model loaded with {len(COCO_INSTANCE_CATEGORY_NAMES)} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Preprocessing and Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "    \"\"\"Load an image and convert to RGB\"\"\"\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_image(img):\n",
    "    \"\"\"Preprocess image for the model\"\"\"\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    # Apply transforms\n",
    "    img_tensor = transform(img)\n",
    "    return img_tensor\n",
    "\n",
    "def get_prediction(img_tensor, threshold=0.5):\n",
    "    \"\"\"Get model prediction\"\"\"\n",
    "    with torch.no_grad():\n",
    "        prediction = model([img_tensor.to(device)])\n",
    "        \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Background Removal Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background(img_path, confidence_threshold=0.7, save_path=None):\n",
    "    \"\"\"Remove background from image using Mask R-CNN\"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = load_image(img_path)\n",
    "    if img is None:\n",
    "        return None, None\n",
    "        \n",
    "    img_tensor = preprocess_image(img)\n",
    "    \n",
    "    # Get predictions\n",
    "    prediction = get_prediction(img_tensor)\n",
    "    \n",
    "    # Convert PIL image to numpy array for processing\n",
    "    img_np = np.array(img)\n",
    "    \n",
    "    # Create a blank mask for the combined objects\n",
    "    height, width = img_np.shape[:2]\n",
    "    combined_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    # Extract masks based on confidence score\n",
    "    masks = prediction['masks']\n",
    "    scores = prediction['scores']\n",
    "    \n",
    "    # Use a threshold to filter out low-confidence predictions\n",
    "    high_confidence_masks = masks[scores > confidence_threshold]\n",
    "    \n",
    "    if len(high_confidence_masks) == 0:\n",
    "        print(f\"No objects detected with confidence threshold {confidence_threshold}\")\n",
    "        return img_np, combined_mask\n",
    "    \n",
    "    # Combine all high-confidence masks\n",
    "    for mask_tensor in high_confidence_masks:\n",
    "        mask = mask_tensor[0].cpu().numpy() > 0.5  # Convert to binary mask\n",
    "        mask = mask.astype(np.uint8) * 255\n",
    "        combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
    "    \n",
    "    # Create a 3-channel mask for bitwise operations\n",
    "    mask_3ch = cv2.merge([combined_mask, combined_mask, combined_mask])\n",
    "    \n",
    "    # Apply mask to keep foreground and make background black\n",
    "    result = cv2.bitwise_and(img_np, mask_3ch)\n",
    "    \n",
    "    # Save result if path is provided\n",
    "    if save_path:\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(result, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    return result, combined_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(original_img, processed_img, mask):\n",
    "    \"\"\"Visualize original image, mask, and processed image\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(original_img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Segmentation Mask')\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Black Background Result')\n",
    "    plt.imshow(processed_img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process a Single Image\n",
    "\n",
    "Let's test our implementation on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your image path\n",
    "sample_img_path = \"path/to/sample_image.jpg\"  # Change this to your image path\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(sample_img_path):\n",
    "    # Load original image\n",
    "    original_img = np.array(load_image(sample_img_path))\n",
    "    \n",
    "    # Process image\n",
    "    processed_img, mask = remove_background(sample_img_path, confidence_threshold=0.7)\n",
    "    \n",
    "    # Visualize results\n",
    "    visualize_results(original_img, processed_img, mask)\n",
    "else:\n",
    "    print(f\"Image not found at {sample_img_path}. Please provide a valid image path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Post-Processing (Optional)\n",
    "\n",
    "The basic Mask R-CNN segmentation might have imperfections at object boundaries. We can use GrabCut to refine the masks for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_mask_grabcut(img, mask, iterations=5):\n",
    "    \"\"\"Refine mask using GrabCut algorithm\"\"\"\n",
    "    # Create a mask for GrabCut\n",
    "    # 0: background, 1: foreground, 2: probable background, 3: probable foreground\n",
    "    grabcut_mask = np.zeros(mask.shape, dtype=np.uint8)\n",
    "    \n",
    "    # Set mask values\n",
    "    grabcut_mask[mask == 0] = 0  # Set definite background\n",
    "    grabcut_mask[mask > 0] = 1    # Set definite foreground\n",
    "    \n",
    "    # Create background and foreground models\n",
    "    bgdModel = np.zeros((1, 65), np.float64)\n",
    "    fgdModel = np.zeros((1, 65), np.float64)\n",
    "    \n",
    "    # Apply GrabCut\n",
    "    rect = (0, 0, img.shape[1], img.shape[0])  # Full image rectangle\n",
    "    cv2.grabCut(img, grabcut_mask, rect, bgdModel, fgdModel, iterations, cv2.GC_INIT_WITH_MASK)\n",
    "    \n",
    "    # Create mask where foreground and probable foreground pixels are 1\n",
    "    refined_mask = np.where((grabcut_mask == 1) | (grabcut_mask == 3), 255, 0).astype('uint8')\n",
    "    \n",
    "    return refined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_refined_mask(img_path, confidence_threshold=0.7, use_grabcut=True, save_path=None):\n",
    "    \"\"\"Process image with optional refinement\"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = load_image(img_path)\n",
    "    if img is None:\n",
    "        return None, None\n",
    "        \n",
    "    img_np = np.array(img)\n",
    "    \n",
    "    # Get basic mask\n",
    "    processed_img, mask = remove_background(img_path, confidence_threshold)\n",
    "    \n",
    "    if use_grabcut and np.any(mask > 0):  # Only apply GrabCut if there's a mask\n",
    "        # Refine mask with GrabCut\n",
    "        refined_mask = refine_mask_grabcut(img_np, mask)\n",
    "        \n",
    "        # Create 3-channel mask\n",
    "        mask_3ch = cv2.merge([refined_mask, refined_mask, refined_mask])\n",
    "        \n",
    "        # Apply refined mask\n",
    "        refined_result = cv2.bitwise_and(img_np, mask_3ch)\n",
    "        \n",
    "        # Save result if path is provided\n",
    "        if save_path:\n",
    "            cv2.imwrite(save_path, cv2.cvtColor(refined_result, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        return refined_result, refined_mask\n",
    "    else:\n",
    "        return processed_img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test advanced processing on the same image if it exists\n",
    "if os.path.exists(sample_img_path):\n",
    "    # Load original image\n",
    "    original_img = np.array(load_image(sample_img_path))\n",
    "    \n",
    "    # Process image with refinement\n",
    "    refined_img, refined_mask = apply_refined_mask(sample_img_path, confidence_threshold=0.7, use_grabcut=True)\n",
    "    \n",
    "    # Visualize results\n",
    "    visualize_results(original_img, refined_img, refined_mask)\n",
    "else:\n",
    "    print(f\"Image not found at {sample_img_path}. Please provide a valid image path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparing Results: Basic vs. Refined\n",
    "\n",
    "Let's compare the results of basic Mask R-CNN segmentation with the refined GrabCut version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(img_path, confidence_threshold=0.7):\n",
    "    \"\"\"Compare basic and refined background removal\"\"\"\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Image not found at {img_path}\")\n",
    "        return\n",
    "    \n",
    "    # Load original image\n",
    "    original_img = np.array(load_image(img_path))\n",
    "    \n",
    "    # Basic processing\n",
    "    basic_img, basic_mask = remove_background(img_path, confidence_threshold)\n",
    "    \n",
    "    # Refined processing\n",
    "    refined_img, refined_mask = apply_refined_mask(img_path, confidence_threshold, use_grabcut=True)\n",
    "    \n",
    "    # Visualize comparison\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Original\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(original_img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Basic mask\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title('Basic Mask R-CNN Mask')\n",
    "    plt.imshow(basic_mask, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Basic result\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.title('Basic Background Removal')\n",
    "    plt.imshow(basic_img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Refined result\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.title('Refined Background Removal (GrabCut)')\n",
    "    plt.imshow(refined_img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results if the sample image exists\n",
    "if os.path.exists(sample_img_path):\n",
    "    compare_results(sample_img_path, confidence_threshold=0.7)\n",
    "else:\n",
    "    print(f\"Image not found at {sample_img_path}. Please provide a valid image path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we've implemented basic and refined background removal using Mask R-CNN and GrabCut algorithms. The key components include:\n",
    "\n",
    "1. Loading a pre-trained Mask R-CNN model\n",
    "2. Processing images to detect objects and generate segmentation masks\n",
    "3. Converting masks to binary format for background removal\n",
    "4. Applying GrabCut refinement for improved edge quality\n",
    "5. Visualizing and comparing the results\n",
    "\n",
    "For batch processing and handling dataset quality issues, please refer to Part 2 of this notebook series."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}