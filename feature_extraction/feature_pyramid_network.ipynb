{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models.detection.backbone_utils import BackboneWithFPN\n",
    "from torchvision.ops import misc as misc_nn_ops\n",
    "from typing import Dict, List\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Set up logging\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Medication Image Feature Extractor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicationFeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Feature extractor for the Parenteral Medication Recognition System.\n",
    "    Uses ResNet50 with Feature Pyramid Network (FPN) to extract multi-scale features\n",
    "    from medication images.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained: bool = True,\n",
    "        returned_layers: List[int] = [1, 2, 3, 4],\n",
    "        extra_blocks=None,\n",
    "        norm_layer=misc_nn_ops.FrozenBatchNorm2d,\n",
    "        trainable_layers: int = 3\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the feature extractor.\n",
    "        \n",
    "        Args:\n",
    "            pretrained: Whether to use pretrained weights\n",
    "            returned_layers: Which ResNet layers to return features from\n",
    "            extra_blocks: Extra blocks to add to FPN\n",
    "            norm_layer: Normalization layer to use\n",
    "            trainable_layers: Number of trainable layers (from the end)\n",
    "        \"\"\"\n",
    "        super(MedicationFeatureExtractor, self).__init__()\n",
    "        \n",
    "        logger.info(\"Initializing MedicationFeatureExtractor with ResNet50FPN backbone\")\n",
    "        \n",
    "        # Load pretrained ResNet50 model\n",
    "        resnet = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # Freeze specific layers if needed\n",
    "        if trainable_layers < 5:\n",
    "            # Freeze layers based on trainable_layers parameter\n",
    "            layers_to_train = [\"layer4\", \"layer3\", \"layer2\", \"layer1\", \"conv1\"][:trainable_layers]\n",
    "            for name, parameter in resnet.named_parameters():\n",
    "                if all([not name.startswith(layer) for layer in layers_to_train]):\n",
    "                    parameter.requires_grad_(False)\n",
    "                    \n",
    "            logger.info(f\"Freezing layers except: {layers_to_train}\")\n",
    "        \n",
    "        # Get list of stage modules from ResNet\n",
    "        return_layers = {f\"layer{k}\": str(v) for v, k in enumerate(returned_layers)}\n",
    "        \n",
    "        # Create the backbone with FPN\n",
    "        self.backbone = BackboneWithFPN(\n",
    "            resnet, \n",
    "            return_layers=return_layers,\n",
    "            in_channels_list=[256, 512, 1024, 2048][:len(returned_layers)],\n",
    "            out_channels=256,\n",
    "            extra_blocks=extra_blocks\n",
    "        )\n",
    "        \n",
    "        # Feature normalization\n",
    "        self.normalization = nn.ModuleDict({\n",
    "            str(i): nn.BatchNorm2d(256) for i in range(len(returned_layers))\n",
    "        })\n",
    "        \n",
    "        # Additional layers for feature enhancement\n",
    "        self.enhancement = nn.ModuleDict({\n",
    "            str(i): nn.Sequential(\n",
    "                nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ) for i in range(len(returned_layers))\n",
    "        })\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        logger.info(f\"MedicationFeatureExtractor initialized with {len(returned_layers)} feature levels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Feature Pyramid Network (FPN) is used to extract multi-scale features through several key components in the code:\n",
    "\n",
    "1. **Creation of the FPN structure** happens in these lines:\n",
    "```python\n",
    "# Create the backbone with FPN\n",
    "self.backbone = BackboneWithFPN(\n",
    "    resnet, \n",
    "    return_layers=return_layers,\n",
    "    in_channels_list=[256, 512, 1024, 2048][:len(returned_layers)],\n",
    "    out_channels=256,\n",
    "    extra_blocks=extra_blocks\n",
    ")\n",
    "```\n",
    "\n",
    "This is where the magic happens. The `BackboneWithFPN` class from torchvision combines the ResNet backbone with an FPN architecture. Here's how it works:\n",
    "\n",
    "2. **Feature extraction at multiple scales** is achieved by:\n",
    "   - `return_layers` mapping specifies which ResNet layers to extract features from (typically layers 1-4)\n",
    "   - `in_channels_list=[256, 512, 1024, 2048]` corresponds to the channel dimensions from these different ResNet layers\n",
    "   - Each layer represents a different scale/resolution of features (earlier layers have higher resolution but less semantic information)\n",
    "\n",
    "3. **FPN structure** adds top-down pathways with lateral connections that:\n",
    "   - Takes high-level features from deeper layers\n",
    "   - Upsamples them and combines them with features from shallower layers\n",
    "   - This creates a feature hierarchy where each level contains both high-resolution and strong semantic information\n",
    "\n",
    "4. **Standardized output channels** is ensured with:\n",
    "   - `out_channels=256` makes all feature maps have the same number of channels (256)\n",
    "   - This standardization allows for consistent processing downstream\n",
    "\n",
    "Then during the forward pass, these multi-scale features are accessed as a dictionary:\n",
    "```python\n",
    "# Extract features using the backbone\n",
    "features = self.backbone(x)\n",
    "```\n",
    "\n",
    "Where each key in the `features` dictionary corresponds to a different scale level, giving you multi-scale feature representation of the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Weight initialization method\n",
    "def _initialize_weights(self):\n",
    "    \"\"\"Initialize weights for enhancement layers.\"\"\"\n",
    "    for m in self.enhancement.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
